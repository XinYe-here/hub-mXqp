### 1. 角色分工与职责

*   **后端开发：** 负责系统的“骨架”与“血肉”。
    *   **职责：** 设计FAQ录入、类目管理、生效时间控制等CRUD接口；处理一级/二级类目的层级逻辑；集成向量数据库与关系型数据库；构建高并发的API服务，确保用户提问后能秒级返回答案。
*   **算法开发：** 负责系统的“大脑”。
    *   **职责：** 文本预处理（清洗、去燥）；选择并微调适合业务场景的语义向量模型；优化检索准确率（Recall）和精度（Precision）；处理冷启动问题及相似问法的扩充。

### 2. 核心问题回答

*   **需要设计数据库吗？**
    **必须设计。** 系统需要两类存储：
    1.  **关系型数据库（如MySQL）：** 存储FAQ原文、答案、类目层级、生效时间、操作日志等结构化信息。
    2.  **向量数据库（如Milvus或ES）：** 存储由模型生成的文本向量（Embedding），用于支持语义层面的“距离计算”和快速检索。

*   **需要使用什么模型？**
    推荐使用 **Sentence-BERT (SBERT)** 或 **BGE** 等双塔模型进行向量化检索。此外，为了提升准确率，可以在初筛后使用 **Cross-Encoder（重排序模型）** 对最相似的Top-K个候选结果进行二次精排。

*   **如何使用BERT的？**
    BERT在此场景中充当“编码器（Encoder）”。
    1.  **离线阶段：** 将库中所有的“标准提问”和“相似提问”输入BERT，提取其特征向量（如取[CLS]位或Mean Pooling），存入向量数据库。
    2.  **在线阶段：** 将用户实时提问输入同一个BERT模型，得到其对应的向量。
    3.  **计算：** 通过余弦相似度（Cosine Similarity）比对用户提问向量与库中向量的距离，定位最匹配的条目。

*   **是否需要使用大模型（LLM）？**
    **非必需，但可作为进阶辅助。**
    传统FAQ匹配主要靠BERT类模型，因为它们成本低、速度快。但在以下场景可以引入大模型：
    1.  **Query改写：** 用户提问不清晰时，利用大模型将口语化提问改写为标准的书面提问。
    2.  **RAG生成：** 匹配到多个知识点时，利用大模型整合答案，生成更人性化的回复，而不仅仅是生硬地返回历史答案。

### 3. 总结

该方案是典型的**检索式问答系统**。后端保障系统的稳定与业务逻辑的严谨（如未生效的FAQ不返回），算法则通过BERT等NLP技术解决“语义鸿沟”，使系统不仅能匹配关键字，更能读懂用户的意图。
